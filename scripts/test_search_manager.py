"""Test SearchManager business logic with Supabase."""

import os
import tempfile
import sys
from pathlib import Path
from dotenv import load_dotenv

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

# Load environment
load_dotenv()

from earthquakes_parser import SupabaseDB, SupabaseFileStorage
from earthquakes_parser.search import SearchManager, GoogleSearcher

print("=" * 60)
print("Test SearchManager Business Logic")
print("=" * 60)

# Initialize components
db = SupabaseDB()
searcher = GoogleSearcher(delay=1.0)
search_manager = SearchManager(db=db, searcher=searcher)
file_storage = SupabaseFileStorage(bucket_name="html-files")

print("\nâœ“ SearchManager initialized")
print("âœ“ Using SupabaseDB for persistence")
print("âœ“ Using GoogleSearcher for keyword search")
print("âœ“ Using SupabaseFileStorage for HTML upload")

# Test 1: Search and save with deduplication
print("\n" + "=" * 60)
print("Test 1: Search and Save with Deduplication")
print("=" * 60)

keywords = ["Ğ·ĞµĞ¼Ğ»ĞµÑ‚Ñ€ÑÑĞµĞ½Ğ¸Ğµ ĞĞ»Ğ¼Ğ°Ñ‚Ñ‹", "earthquake Kazakhstan"]

print(f"\nâ³ Searching for keywords: {keywords}")
print("   Max results: 3 per keyword")
print("   Deduplication: enabled")

stats = search_manager.search_and_save(
    keywords=keywords, max_results=3, skip_existing=True
)

print(f"\nğŸ“Š Results:")
print(f"   âœ“ Keywords searched: {stats['searched']}")
print(f"   âœ“ Total results found: {stats['found']}")
print(f"   âœ“ New results saved: {stats['new']}")
print(f"   âœ“ Existing skipped: {stats['skipped']}")

# Test 2: Download HTML for pending URLs
print("\n" + "=" * 60)
print("Test 2: Download HTML for Pending URLs")
print("=" * 60)

print("\nâ³ Downloading HTML with Selenium...")
download_stats = search_manager.download_html(
    storage=file_storage,
    fetch_with="selenium",
    limit=5
)

print(f"\nğŸ“Š Download Results:")
print(f"   âœ“ HTML downloaded: {download_stats['downloaded']}")
print(f"   âœ— Failed downloads: {download_stats['failed']}")

# Test 3: Get statistics
print("\n" + "=" * 60)
print("Test 3: Get Search Statistics")
print("=" * 60)

print("\nâ³ Fetching statistics...")
stats = search_manager.get_statistics()

print("\nğŸ“Š Database Statistics:")
print(f"   Total records: {stats['total']}")
print(f"   Pending: {stats['pending']}")
print(f"   Downloaded: {stats['downloaded']}")
print(f"   Parsed: {stats['parsed']}")
print(f"   Analyzed: {stats['analyzed']}")
print(f"   Failed: {stats['failed']}")

# Test 4: Search from keywords file
print("\n" + "=" * 60)
print("Test 4: Search with Keywords File")
print("=" * 60)

# Create temporary keywords file
with tempfile.NamedTemporaryFile(
    mode="w", suffix=".txt", delete=False, encoding="utf-8"
) as f:
    f.write("Ğ·ĞµĞ¼Ğ»ĞµÑ‚Ñ€ÑÑĞµĞ½Ğ¸Ğµ\n")
    f.write("ÑĞµĞ¹ÑĞ¼Ğ¾Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ\n")
    keywords_file = f.name

print(f"\nâ³ Created test keywords file: {keywords_file}")
print("   Keywords: Ğ·ĞµĞ¼Ğ»ĞµÑ‚Ñ€ÑÑĞµĞ½Ğ¸Ğµ, ÑĞµĞ¹ÑĞ¼Ğ¾Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ")

stats = search_manager.search_with_keywords_file(
    keywords_file, max_results=2, skip_existing=True
)

print(f"\nğŸ“Š Results:")
print(f"   âœ“ Keywords searched: {stats['searched']}")
print(f"   âœ“ Total results found: {stats['found']}")
print(f"   âœ“ New results saved: {stats['new']}")
print(f"   âœ“ Existing skipped: {stats['skipped']}")

# Clean up
os.remove(keywords_file)
print(f"\nâœ“ Cleaned up test file")

# Final summary
print("\n" + "=" * 60)
print("âœ… All SearchManager tests completed!")
print("=" * 60)

print("\nğŸ“ SearchManager Features Demonstrated:")
print("   1. âœ… Search and save with automatic deduplication")
print("   2. âœ… Download HTML with modular fetcher (bs4 or selenium)")
print("   3. âœ… Get comprehensive statistics")
print("   4. âœ… Search from keywords file")

print("\nğŸ¯ Business Logic Benefits:")
print("   â€¢ Automatic deduplication prevents duplicate URLs")
print("   â€¢ Status tracking enables pipeline workflow")
print("   â€¢ Statistics provide visibility into data")
print("   â€¢ Modular design supports flexible workflows")
